\def\Amat{\begin{bmatrix}
    5 &  3 &  6 &  7 &  6 \\
    4 &  5 &  7 &  1 &  3 \\
    5 &  7 &  6 &  1 &  0 \\
    6 & 10 & 12 & 12 & 11 \\
    9 & 10 & 12 & 13 &  9 \\
\end{bmatrix}}
Consider the following matrix
\begin{equation}
    A = \Amat.
\end{equation}
The column means are \(\mu = [5.8,7,8.6,6.8,5.8]\).
Then the mean-centered data becomes
\def\-{\phantom{-}}
\begin{equation}
    A_0 = A - \mu = \frac{1}{5}\begin{bmatrix}
        -4 &   -20 &   -13 &   \-1 &   \-1 \\
        -9 &   -10 &    -8 &   -29 &   -14 \\
        -4 &   \-0 &   -13 &   -29 &   -29 \\
        \-1 &  \-15 &  \-17 &  \-26 &  \-26 \\
    \-16 &  \-15 &  \-17 &  \-31 &  \-16 \\
\end{bmatrix}.
\end{equation}

The covariance matrix is
\begin{equation}C = A_0^\top A_0 = \frac{1}{5}\begin{bmatrix}
        74 &  85 &  93 & 179 & 104 \\
        85 & 190 & 170 & 225 & 150 \\
        93 & 170 & 196 & 313 & 238 \\
    179 & 225 & 313 & 664 & 484 \\
    104 & 150 & 238 & 484 & 394 \\
\end{bmatrix}.\end{equation}

Diagonalizing \(C\) gives
\begin{align*}
    V &= \begin{bmatrix}
        0.1888 & -0.2020 & -0.6366 &  0.5495 & -0.4651\\
        0.2755 & -0.7886 &  0.1472 & -0.4502 & -0.2791\\
        0.3606 & -0.3464 &  0.3128 &  0.5836 &  0.5582\\
        0.6979 &  0.2522 & -0.4422 & -0.3707 &  0.3411\\
        0.5209 &  0.3922 &  0.5288 &  0.1316 & -0.5271\\
    \end{bmatrix},\\
    D &= \begin{bmatrix}
        264.8458 &       0 &      0 &      0 & 0 \\
                0 & 27.9766 &      0 &      0 & 0 \\
                0 &       0 & 9.3198 &      0 & 0 \\
                0 &       0 &      0 & 1.4579 & 0 \\
                0 &       0 &      0 &      0 & 0 \\
    \end{bmatrix}.
\end{align*}

If we keep all \(5\) principal component vectors, then \(V_5 = V\) and the projection of \(A_0\) along \(V\) is
\begin{equation}B = A_0 V = \begin{bmatrix}
    -1.9469 &  4.3453 & -0.8756 & -0.2039 & 0 \\
    -6.9742 & -0.0660 &  1.4352 &  0.7590 & 0 \\
    -8.1577 & -2.6752 & -0.8063 & -0.5704 & 0 \\
        8.4282 & -0.2330 &  1.8282 & -0.4996 & 0 \\
        8.6507 & -1.3711 & -1.5815 &  0.5149 & 0 \\
\end{bmatrix}.\end{equation}
Here, the last column of \(B\) is the zero vector because the last eigenvalue of \(C\) is zero\footnote{Since we subtracted the column means from a square matrix \(A\), the dimension of the row space was reduced to 4.}.
To perfectly reconstruct \(A\), we need \(k = 4\) principal components and the row vector \(\mu\)
\begin{equation}A = B V^\top + \mu = B V_4^\top + \mu.\end{equation}

If we use \(k = 3\) principal components, then the projection of \(A_0\) onto \(V_3\) is
\begin{equation}B = A_0 V_3 = \begin{bmatrix}
    -1.9469 &  4.3453 & -0.8756 \\
    -6.9742 & -0.0660 &  1.4352 \\
    -8.1577 & -2.6752 & -0.8063 \\
        8.4282 & -0.2330 &  1.8282 \\
        8.6507 & -1.3711 & -1.5815 \\
\end{bmatrix}\end{equation}
and \(A\) is approximately reconstructed by
\begin{equation}A \approx B V_3^\top + \mu = \begin{bmatrix}
    % 5.1121 &  2.9082 &  6.1190 &  6.9244 &  6.0268 \\
    % 3.5829 &  5.3417 &  6.5570 &  1.2814 &  2.9001 \\
    % 5.3134 &  6.7432 &  6.3329 &  0.7886 &  0.0751 \\
    % 6.2745 &  9.7751 & 12.2916 & 11.8148 & 11.0658 \\
    % 8.7170 & 10.2318 & 11.6995 & 13.1909 &  8.9322 \\
    5.1 &  2.9 &  6.1 &  6.9 &  6.0 \\
    3.6 &  5.3 &  6.6 &  1.3 &  2.9 \\
    5.3 &  6.7 &  6.3 &  0.8 &  0.1 \\
    6.3 &  9.8 & 12.3 & 11.8 & 11.1 \\
    8.7 & 10.2 & 11.7 & 13.2 &  8.9 \\
\end{bmatrix}.\end{equation}
We can compute the reconstruction error using the Frobenius norm
\begin{equation*}%\label{eqn:reconstruction_error}
    E_k = \|A - (V_k^\top + \mu)\|_F.
\end{equation*}
By the SVD, we have \(A_0 = USV^\top\), where \(S = \sqrt{D}\).
So, the projection of \(A_0\) onto \(V_p\) is \begin{equation}B = A_0 V_p = U S_p,\end{equation} where \(S_p\) is the diagonal matrix of the first \(p\) singular values.
Then the reconstruction error becomes
\begin{align*}
    \|A - (BV_p^\top + \mu)\|_F
    &= \|(A - \mu) - BV_p^\top\|_F \\
    &= \|A_0 - BV_p^\top\|_F \\
    &= \|USV^\top - US_pV^\top\|_F \\
    &= \|U(S - S_p)V^\top\|_F \\
    &= \|S-S_p\|_F \\
    &= \sqrt{\sigma_{p+1}^2 + \dots + \sigma_{d}^2}.
\end{align*}
Hence,
\begin{equation}E_3 = \sigma_3 + \sigma_4 = \sqrt{1.4579^2 + 0^2} = 1.2074.\end{equation}