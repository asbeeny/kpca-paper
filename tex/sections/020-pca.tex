\begin{itemize}
    \item describe the goal of PCA
    \item PCA as a rotation and rescaling
    \item show PCA minimizes projection residuals
    \item PCA algorithm
    \item PCA example (old)
\end{itemize}

\begin{example}
    \def\Amat{\begin{bmatrix}
        5 &  3 &  6 &  7 &  6 \\
        4 &  5 &  7 &  1 &  3 \\
        5 &  7 &  6 &  1 &  0 \\
        6 & 10 & 12 & 12 & 11 \\
        9 & 10 & 12 & 13 &  9 \\
    \end{bmatrix}}
    Consider the following matrix \[A = \Amat.\]
    The column means are \(\mu = [5.8,7,8.6,6.8,5.8]\).
    Then the mean-centered data becomes
    \def\-{\phantom{-}}
    \[X = A - \mu = \frac{1}{5}\begin{bmatrix}
            -4 &   -20 &   -13 &   \-1 &   \-1 \\
            -9 &   -10 &    -8 &   -29 &   -14 \\
            -4 &   \-0 &   -13 &   -29 &   -29 \\
            \-1 &  \-15 &  \-17 &  \-26 &  \-26 \\
        \-16 &  \-15 &  \-17 &  \-31 &  \-16 \\
    \end{bmatrix}.\]

    The covariance matrix is
    \[C = X^TX = \frac{1}{5}\begin{bmatrix}
            74 &  85 &  93 & 179 & 104 \\
            85 & 190 & 170 & 225 & 150 \\
            93 & 170 & 196 & 313 & 238 \\
        179 & 225 & 313 & 664 & 484 \\
        104 & 150 & 238 & 484 & 394 \\
    \end{bmatrix}.\]
    
    Diagonalizing \(C\) gives
    \begin{align*}
        V &= \begin{bmatrix}
            0.1888 & -0.2020 & -0.6366 &  0.5495 & -0.4651\\
            0.2755 & -0.7886 &  0.1472 & -0.4502 & -0.2791\\
            0.3606 & -0.3464 &  0.3128 &  0.5836 &  0.5582\\
            0.6979 &  0.2522 & -0.4422 & -0.3707 &  0.3411\\
            0.5209 &  0.3922 &  0.5288 &  0.1316 & -0.5271\\
        \end{bmatrix},\\
        D &= \begin{bmatrix}
            264.8458 &       0 &      0 &      0 & 0 \\
                    0 & 27.9766 &      0 &      0 & 0 \\
                    0 &       0 & 9.3198 &      0 & 0 \\
                    0 &       0 &      0 & 1.4579 & 0 \\
                    0 &       0 &      0 &      0 & 0 \\
        \end{bmatrix}.
    \end{align*}
    
    If we keep all \(5\) principal component vectors, then \(V_5 = V\) and the projection of \(X\) along \(V\) is
    \[P = XV = \begin{bmatrix}
        -1.9469 &  4.3453 & -0.8756 & -0.2039 & 0 \\
        -6.9742 & -0.0660 &  1.4352 &  0.7590 & 0 \\
        -8.1577 & -2.6752 & -0.8063 & -0.5704 & 0 \\
            8.4282 & -0.2330 &  1.8282 & -0.4996 & 0 \\
            8.6507 & -1.3711 & -1.5815 &  0.5149 & 0 \\
    \end{bmatrix}.\]
    Here, the last column of \(P\) is the zero vector because the last eigenvalue of \(C\) is zero\footnote{Since we subtracted the column means from a square matrix \(A\), the dimension of the row space was reduced to 4.}.
    To perfectly reconstruct \(A\), we need \(k = 4\) principal components and the row vector \(\mu\)
    \[A = PV^T + \mu = PV_4^T + \mu.\]
    
    If we use \(k = 3\) principal components, then the projection of \(X\) onto \(V_3\) is
    \[P = XV_3 = \begin{bmatrix}
        -1.9469 &  4.3453 & -0.8756 \\
        -6.9742 & -0.0660 &  1.4352 \\
        -8.1577 & -2.6752 & -0.8063 \\
            8.4282 & -0.2330 &  1.8282 \\
            8.6507 & -1.3711 & -1.5815 \\
    \end{bmatrix}\]
    and \(A\) is approximately reconstructed by
    \[A \approx P V_3^T + \mu = \begin{bmatrix}
        % 5.1121 &  2.9082 &  6.1190 &  6.9244 &  6.0268 \\
        % 3.5829 &  5.3417 &  6.5570 &  1.2814 &  2.9001 \\
        % 5.3134 &  6.7432 &  6.3329 &  0.7886 &  0.0751 \\
        % 6.2745 &  9.7751 & 12.2916 & 11.8148 & 11.0658 \\
        % 8.7170 & 10.2318 & 11.6995 & 13.1909 &  8.9322 \\
        5.1 &  2.9 &  6.1 &  6.9 &  6.0 \\
        3.6 &  5.3 &  6.6 &  1.3 &  2.9 \\
        5.3 &  6.7 &  6.3 &  0.8 &  0.1 \\
        6.3 &  9.8 & 12.3 & 11.8 & 11.1 \\
        8.7 & 10.2 & 11.7 & 13.2 &  8.9 \\
    \end{bmatrix}.\]
    We can compute the reconstruction error using
    \begin{equation*}%\label{eqn:reconstruction_error}
        E_k = \|A - (PV_k^T + \mu)\|_F,
    \end{equation*}
    where \(\|\cdot\|_F\) is the Frobenius norm.
    By the SVD, we have \(X = USV^T\), where \(S = \sqrt{D}\).
    So, the projection of \(X\) onto \(V_k\) is \[P = XV_k = US_k,\] where \(S_k\) is the diagonal matrix of the first \(k\) singular values.
    Then the reconstruction error becomes
    \begin{align*}
        \|A - (PV_k^T + \mu)\|_F
        &= \|(A - \mu) - PV_k^T\|_F \\
        &= \|X - PV_k^T\|_F \\
        &= \|USV^T - US_kV^T\|_F \\
        &= \|U(S - S_k)V^T\|_F \\
        &= \|S-S_k\|_F \\
        &= \sigma_k + \sigma_{k+1} + \dots + \sigma_{p}.
    \end{align*}
    Hence,
    \[E_3 = \sigma_3 + \sigma_4 = \sqrt{1.4579} + 0 = 1.2074.\]
\end{example}